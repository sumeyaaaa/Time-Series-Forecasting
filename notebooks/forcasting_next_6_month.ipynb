{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a144bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63848428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc456b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import necessary libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.yf_tesla_modeling import find_best_arima_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720a824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and prepared successfully!\n",
      "Here are the first 5 rows of your clean TSLA data:\n",
      "            Adj Close\n",
      "Date                 \n",
      "2015-07-01  17.943333\n",
      "2015-07-02  18.667999\n",
      "2015-07-03  18.667999\n",
      "2015-07-06  18.648001\n",
      "2015-07-07  17.858667\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\data\\combined_2015-07-01_to_2025-08-01.csv\")\n",
    "# --- 2. Prepare the DataFrame ---\n",
    "# Convert the 'Date' column into a proper datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Set the 'Date' column as the index, which is standard for time series analysis\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# --- 3. Select and Clean the TSLA Data (as we discussed) ---\n",
    "# Now you can select the 'TSLA.Adj Close' column, which we know exists\n",
    "tsla_df = data[['TSLA.Adj Close']]\n",
    "\n",
    "# Rename the column to make the rest of the code simpler\n",
    "tsla_df = tsla_df.rename(columns={'TSLA.Adj Close': 'Adj Close'})\n",
    "\n",
    "# Clean the data to ensure business day frequency and fill gaps\n",
    "tsla_df = tsla_df.asfreq('B').ffill().bfill()\n",
    "\n",
    "\n",
    "# --- 4. Verify the result ---\n",
    "print(\"Data loaded and prepared successfully!\")\n",
    "print(\"Here are the first 5 rows of your clean TSLA data:\")\n",
    "print(tsla_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff291540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running auto_arima to find the best model parameters...\n",
      "Performing stepwise search to minimize aic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=14066.624, Time=1.13 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=14065.901, Time=0.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=14065.756, Time=0.18 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=14065.762, Time=0.23 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=14064.621, Time=0.10 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 1.772 seconds\n",
      "\n",
      "Best ARIMA order found: (0, 1, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split_date = '2024-01-01'\n",
    "train = tsla_df[tsla_df.index < split_date]\n",
    "test = tsla_df[tsla_df.index >= split_date]\n",
    "# Cell 3: Call the function and get the best order\n",
    "# Pass the correct Series to your function\n",
    "# Corrected code with .dropna()\n",
    "auto_model = find_best_arima_params(train['Adj Close'])\n",
    "\n",
    "# .order is an attribute (a variable), not a function. You access it directly.\n",
    "best_order = auto_model.order \n",
    "\n",
    "print(f\"\\nBest ARIMA order found: {best_order}\")\n",
    "# --- 2. LSTM Data Preparation ---\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_data = scaler.fit_transform(train)\n",
    "scaled_test_data = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "598eb0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained LSTM model loaded successfully.\n",
      "\n",
      "Generating forecast for the next 252 trading days...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast generation complete.\n",
      "\n",
      "--- First 5 Days of Future Forecast ---\n",
      "              Forecast\n",
      "2025-08-01  291.193817\n",
      "2025-08-04  291.193817\n",
      "2025-08-05  291.193817\n",
      "2025-08-06  291.193817\n",
      "2025-08-07  291.193817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- ASSUMPTIONS ---\n",
    "# This script assumes you have the following variables from your previous steps:\n",
    "# - scaler: The fitted MinMaxScaler object.\n",
    "# - tsla_df: The full, cleaned DataFrame of historical TSLA prices.\n",
    "\n",
    "# --- 1. Define the time_step ---\n",
    "# This must be an integer. We will use 60 as it's a common standard.\n",
    "time_step = 60\n",
    "\n",
    "# --- 2. Load the Trained Model ---\n",
    "model_filepath = r'C:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\models\\tsla_lstm_model.keras'\n",
    "trained_model = tf.keras.models.load_model(model_filepath)\n",
    "print(\"Trained LSTM model loaded successfully.\")\n",
    "\n",
    "# --- 3. Prepare the Initial Input for Forecasting ---\n",
    "# We need the last 'time_step' days from our historical data to start the forecast.\n",
    "last_sequence = tsla_df['Adj Close'][-time_step:].values.reshape(-1, 1)\n",
    "\n",
    "# Scale this initial input\n",
    "scaled_last_sequence = scaler.transform(last_sequence)\n",
    "\n",
    "# --- 4. Iterative Forecasting Loop ---\n",
    "future_predictions = []\n",
    "current_input = scaled_last_sequence.reshape(1, time_step, 1)\n",
    "forecast_days = 252  # Approximately 1 year of trading days\n",
    "\n",
    "print(f\"\\nGenerating forecast for the next {forecast_days} trading days...\")\n",
    "\n",
    "for _ in range(forecast_days):\n",
    "    # Predict the next day\n",
    "    next_prediction_scaled = trained_model.predict(current_input, verbose=0)\n",
    "    \n",
    "    # Store the scaled prediction\n",
    "    future_predictions.append(next_prediction_scaled[0, 0])\n",
    "    \n",
    "    # Update the input sequence for the next prediction\n",
    "   # Corrected code\n",
    "# Reshape the 2D prediction to 3D before appending\n",
    "current_input = np.append(current_input[:, 1:, :], next_prediction_scaled.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "# --- 5. Finalize the Forecast ---\n",
    "# Inverse transform all predictions at once\n",
    "future_forecast_values = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "\n",
    "# Create a future date index for the forecast\n",
    "last_date = tsla_df.index[-1]\n",
    "future_date_index = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=forecast_days)\n",
    "\n",
    "# Create the final forecast DataFrame\n",
    "future_forecast_df = pd.DataFrame(future_forecast_values, index=future_date_index, columns=['Forecast'])\n",
    "\n",
    "print(\"Forecast generation complete.\")\n",
    "print(\"\\n--- First 5 Days of Future Forecast ---\")\n",
    "print(future_forecast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eaded9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and built successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel loaded and built successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# --- The rest of your code will now work ---\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Create a new model that runs the base model in training mode (dropout active)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m inputs = tf.keras.Input(shape=(\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m.shape[\u001b[32m1\u001b[39m], base_model.input.shape[\u001b[32m2\u001b[39m]))\n\u001b[32m     30\u001b[39m outputs = base_model(inputs, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     31\u001b[39m mc_model = tf.keras.Model(inputs, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:272\u001b[39m, in \u001b[36mOperation.input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[32m    265\u001b[39m \n\u001b[32m    266\u001b[39m \u001b[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m \u001b[33;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_tensors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:303\u001b[39m, in \u001b[36mOperation._get_node_attribute_at_index\u001b[39m\u001b[34m(self, node_index, attr, attr_name)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[32m    288\u001b[39m \n\u001b[32m    289\u001b[39m \u001b[33;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m \u001b[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inbound_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    304\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has never been called \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m     )\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes) > node_index:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at node \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but the operation has only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inbound nodes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Load Model and Prepare Data ---\n",
    "# This assumes 'scaler' and 'tsla_df' are already loaded from your previous work.\n",
    "# And that 'time_step' is defined (e.g., 60).\n",
    "# --- 1. Define the time_step ---\n",
    "# This must be an integer. We will use 60 as it's a common standard.\n",
    "time_step = 10\n",
    "\n",
    "model_filepath = r'C:\\Users\\ABC\\Desktop\\10Acadamy\\week_11\\Time-Series-Forecasting\\models\\tsla_lstm_model.keras'\n",
    "# To use Monte Carlo Dropout, we need to reload the model to access the underlying layers\n",
    "# --- Load the Model ---\n",
    "base_model = tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "# --- Add this line to FIX the error ---\n",
    "# This tells the model its expected input shape.\n",
    "# (None = flexible batch size, time_step = your look-back, 1 = number of features)\n",
    "# Corrected code\n",
    "base_model.build(input_shape=(None, time_step, 1))\n",
    "\n",
    "print(\"Model loaded and built successfully.\")\n",
    "\n",
    "# --- The rest of your code will now work ---\n",
    "# Create a new model that runs the base model in training mode (dropout active)\n",
    "inputs = tf.keras.Input(shape=(base_model.input.shape[1], base_model.input.shape[2]))\n",
    "outputs = base_model(inputs, training=True)\n",
    "mc_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Create a new model that runs the base model in training mode (dropout active)\n",
    "\n",
    "\n",
    "print(\"Trained LSTM model loaded for Monte Carlo forecasting.\")\n",
    "\n",
    "# --- 2. Monte Carlo Iterative Forecasting ---\n",
    "# We will run the forecast 50 times to get a distribution of possible outcomes.\n",
    "n_iterations = 50\n",
    "forecast_days = 180 # Approx. 6 months\n",
    "time_step = 10 # Ensure this matches your model's training\n",
    "\n",
    "# Prepare the initial input sequence from the last known data\n",
    "last_sequence = tsla_df['Adj Close'][-time_step:].values.reshape(-1, 1)\n",
    "scaled_last_sequence = scaler.transform(last_sequence)\n",
    "\n",
    "# Store all the different forecast paths\n",
    "all_forecast_paths = []\n",
    "\n",
    "print(f\"\\nRunning {n_iterations} Monte Carlo simulations for a {forecast_days}-day forecast...\")\n",
    "\n",
    "for _ in tqdm(range(n_iterations), desc=\"Forecasting Progress\"):\n",
    "    current_input = scaled_last_sequence.reshape(1, time_step, 1)\n",
    "    future_predictions_single_run = []\n",
    "    \n",
    "    for _ in range(forecast_days):\n",
    "        next_prediction_scaled = mc_model.predict(current_input, verbose=0)\n",
    "        future_predictions_single_run.append(next_prediction_scaled[0, 0])\n",
    "        current_input = np.append(current_input[:, 1:, :], next_prediction_scaled.reshape(1, 1, 1), axis=1)\n",
    "        \n",
    "    all_forecast_paths.append(future_predictions_single_run)\n",
    "\n",
    "# --- 3. Process the Forecasts to Get Mean and Confidence Intervals ---\n",
    "# Convert paths to a NumPy array for easier calculation\n",
    "all_forecast_paths = np.array(all_forecast_paths)\n",
    "\n",
    "# Inverse transform all paths at once to get real dollar values\n",
    "all_forecast_paths_unscaled = scaler.inverse_transform(all_forecast_paths.T).T\n",
    "\n",
    "# Calculate the mean forecast and the confidence interval bounds (e.g., 95% interval)\n",
    "mean_forecast = np.mean(all_forecast_paths_unscaled, axis=0)\n",
    "lower_bound = np.percentile(all_forecast_paths_unscaled, 2.5, axis=0)\n",
    "upper_bound = np.percentile(all_forecast_paths_unscaled, 97.5, axis=0)\n",
    "\n",
    "# Create a future date index\n",
    "last_date = tsla_df.index[-1]\n",
    "future_date_index = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=forecast_days)\n",
    "\n",
    "# Create the final forecast DataFrame\n",
    "future_forecast_df = pd.DataFrame({\n",
    "    'Forecast': mean_forecast,\n",
    "    'Lower_CI': lower_bound,\n",
    "    'Upper_CI': upper_bound\n",
    "}, index=future_date_index)\n",
    "\n",
    "print(\"Forecast and confidence intervals generated successfully.\")\n",
    "\n",
    "# --- 4. Visualize the Forecast with Confidence Intervals ---\n",
    "# We will plot the last year of historical data for context\n",
    "historical_data_to_plot = tsla_df.loc[tsla_df.index > (tsla_df.index.max() - pd.DateOffset(years=1))]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the historical data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=historical_data_to_plot.index, y=historical_data_to_plot['Adj Close'],\n",
    "    mode='lines', name='Historical Price', line=dict(color='royalblue')\n",
    "))\n",
    "\n",
    "# Add the lower and upper confidence interval bounds\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=future_forecast_df.index, y=future_forecast_df['Upper_CI'],\n",
    "    mode='lines', name='Upper 95% CI', line=dict(width=0)\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=future_forecast_df.index, y=future_forecast_df['Lower_CI'],\n",
    "    mode='lines', name='Lower 95% CI', line=dict(width=0),\n",
    "    fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)' # Fill the area between upper and lower\n",
    "))\n",
    "\n",
    "# Add the mean forecast line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=future_forecast_df.index, y=future_forecast_df['Forecast'],\n",
    "    mode='lines', name='Mean Forecast', line=dict(color='orange', width=3)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='TSLA 6-Month Future Forecast with 95% Confidence Interval',\n",
    "    xaxis_title='Date', yaxis_title='Adjusted Close Price',\n",
    "    template='plotly_white', legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28a4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Time-Series-Forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
